meta:
- desc: |
   Run ceph on two nodes, using one of them as a client,
   with a separate client-only node. 
   Use xfs beneath the osds.
   install -x latest version
   expected -x must be a post-jewel branch, e.g. jewel or master
   run workload and upgrade-sequence in parallel
   install/downgrade to ceph/v10.2.0 point version
   run workload and upgrade-sequence in parallel
overrides:
  ceph:
    log-whitelist:
    - reached quota
    - scrub
    - osd_map_max_advance
    - failed to encode
    - wrongly marked
    fs: xfs
    conf:
      mon:
        mon debug unsafe allow tier with nonempty snaps: true
      osd:
        osd map max advance: 1000
roles:
- - mon.a
  - mds.a
  - osd.0
  - osd.1
  - osd.2
- - mon.b
  - mon.c
  - osd.3
  - osd.4
  - osd.5
  - client.0
- - client.1
openstack:
- volumes: # attached to each instance
    count: 3
    size: 30 # GB
tasks:
- print: "****  -x about to install"
- install:
    # install -x
    #branch: jewel
- print: "**** done jewel tip install"
- ceph:
   fs: xfs
- print: "**** done ceph xfs"
- sequential:
   - workload
- print: "**** done workload jewel tip"
- install.upgrade:
    mon.a:
      tag: v10.2.0
    mon.b:
      tag: v10.2.0
- print: "**** done downgrade to v10.2.0"
- parallel:
   - workload_v10.2.0
   - upgrade-sequence_v10.2.0
- install.upgrade:
    client.1:
       tag: v10.2.0
- print: "**** install.upgrade v10.2.0 on client.1"
- workunit:
    clients:
      client.1:
      - rados/test.sh
      - cls
- print: "**** done test on v10.2.0 cluster"
#######################
workload:
   sequential:
   - workunit:
       clients:
         client.0:
           - suites/blogbench.sh
   - print: "**** done initial workload test"
workload_v10.2.0:
   full_sequential:
   - workunit:
       tag: v10.2.0
       clients:
         client.1:
         - rados/test.sh
         - cls
   - print: "**** done rados/test.sh &  cls workload_v10.2.0"
   - sequential:
     - rgw: [client.0]
     - print: "**** done rgw workload_v10.2.0"
     - s3tests:
         client.0:
           force-branch: ceph-jewel
           rgw_server: client.0
     - print: "**** done s3tests workload_v10.2.0"
upgrade-sequence_v10.2.0:
   sequential:
   - print: "**** done v10.2.0 install.upgrade"
   - ceph.restart: [mds.a]
   - sleep:
       duration: 60
   - ceph.restart: [osd.0]
   - sleep:
       duration: 30
   - ceph.restart: [osd.1]
   - sleep:
       duration: 30
   - ceph.restart: [osd.2]
   - sleep:
       duration: 30
   - ceph.restart: [osd.3]
   - sleep:
       duration: 30
   - ceph.restart: [osd.4]
   - sleep:
       duration: 30
   - ceph.restart: [osd.5]
   - sleep:
       duration: 60
   - ceph.restart: [mon.a]
   - sleep:
       duration: 60
   - ceph.restart: [mon.b]
   - sleep:
       duration: 60
   - ceph.restart: [mon.c]
   - sleep:
       duration: 60
   - print: "**** done ceph.restart all v10.2.0 mds/osd/mon"
