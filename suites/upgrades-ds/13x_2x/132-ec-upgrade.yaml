overrides:
  ceph-deploy:
    prepare_activate: true
    conf:
      client:
        log file: /var/log/ceph/ceph-$name.$pid.log
      mon:
        debug mon: 1
        debug ms: 20
        debug paxos: 20
      osd:
        debug filestore: 20
        debug journal: 20
        debug ms: 1
        debug osd: 20
      global:
        mon pg warn min per osd: 2
        osd pool default size: 2
roles:
- - mon.a
  - mon.b
  - mon.c
  - osd.0
  - osd.1
- - osd.2
  - osd.3
- - client.0
tasks:
- ssh-keys:
- ceph-deploy:
    rhbuild: '1.3.2' 
    fs: xfs
- exec:
    client.0:
    - ceph osd erasure-code-profile set teuthologyprofile ruleset-failure-domain=osd
      k=2 m=1
    - ceph osd pool create base-pool 4 4 erasure teuthologyprofile
- exec:
    client.0:
    - ceph osd pool create cache-pool 4
    - ceph osd tier add base-pool cache-pool
    - ceph osd tier cache-mode cache-pool writeback
    - ceph osd tier set-overlay base-pool cache-pool
    - ceph osd pool set cache-pool hit_set_type bloom
    - ceph osd pool set cache-pool hit_set_count 8
    - ceph osd pool set cache-pool hit_set_period 5
- parallel:
  - workload-when-upgrading
  - upgrade-sequence
- print: '**** done upgrade'
- parallel:
  - workload-2
  - flip-and-success
upgrade-first-half:
  sequential:
  - ceph-deploy.upgrade:
      latest: true
      roles:
       - mon.a
  - sleep:
      duration: 60
upgrade-second-half:
  sequential:
  - ceph-deploy.upgrade:
      latest: true
      roles:
       - osd.2
upgrade-sequence:
  sequential:
  - upgrade-first-half
  - flip-but-fail
  - upgrade-second-half
workload-2:
  sequential:
  - rados:
      clients:
      - client.0
      objects: 50
      op_weights:
        delete: 50
        read: 100
        rollback: 50
        snap_create: 50
        snap_remove: 50
        write: 100
      ops: 1000
      pools:
      - base-pool
  - print: '**** done rados after upgrading'
workload-when-upgrading:
  sequential:
  - rados:
      clients:
      - client.0
      objects: 50
      op_weights:
        append: 100
        copy_from: 50
        delete: 50
        read: 100
        rmattr: 25
        setattr: 25
        write: 0
      ops: 4000
      pools:
      - base-pool
      write_append_excl: false
flip-and-success:
  sequential:
  - exec:
      client.0:
      - ceph osd set sortbitwise
      - ceph osd pool set cache-pool use_gmt_hitset true
  - print: '**** done flip-and-success'
flip-but-fail:
  sequential:
  - exec:
      mon.a:
      - ceph osd set sortbitwise 2>&1 | grep "not all up OSDs have OSD_BITWISE_HOBJ_SORT
        feature"
  - print: '**** done flip-but-fail'
